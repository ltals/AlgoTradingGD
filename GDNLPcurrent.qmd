---
title: "NLPGD"
format: html
editor: visual
---

## Quarto

Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see <https://quarto.org>.

## Running Code

When you click the **Render** button a document will be generated that includes both content and the output of embedded code. You can embed code like this:

```{r}
library(tidyverse)
library(ggplot2)
library(tidyquant)
library(plotly)
library(data.table)
library(lubridate)
library(zoo)
library(tidytext)
library(textdata)
library(fintool)
#github: jvlahadamis/fintool

bp <- read_csv("BP.csv") %>% 
  mutate(i = row_number())
chevron <- read_csv("chevron.csv") %>% 
  mutate(i = row_number())
exxon <- read_csv("exxonmobil.csv") %>% 
  mutate(i = row_number())
shell <- read_csv("Shell.csv") %>% 
  mutate(i = row_number())


# my os seems to import them as ...1, hence comment out
bp <- bp %>% 
  #select(-X)
  select(-`...1`)
shell <- shell %>%
  #select(-X)
  select(-`...1`)

# prep dataframe
ratings <- rbind(bp, shell, exxon, chevron)
ratings <- ratings %>%
  mutate('Company' = name1, 
         'reviewtext' = reviewBody,
         'Rating' = ratingValue,
         #lubridate method was giving a parsing error for 3, this way seems quiter
          date = as.Date(date, format = "%b %d, %Y")) %>%
          transmute(Company, name, Rating, reviewtext, date)
```

```{r}
# start playing around with sentiment
# afinn
afinn <- tidytext::get_sentiments('afinn')

afinn_nlp <- ratings %>%
  select(date, Company, reviewtext) %>%
  filter(date > "2016-01-01") %>% 
  unnest_tokens(output = word, input = reviewtext) %>% 
  inner_join(afinn) %>%
  mutate(month = (ceiling_date(date, unit = 'month') - days(1))) %>% 
  group_by(month, Company) %>%
  summarise(sentiment = mean(value), .groups = 'keep') 

afinn_nlp %>% 
  ggplot(aes(x = month, y = sentiment, col = Company)) + geom_bar(stat = 'identity') + facet_wrap(~Company)

#unsummarised base files used to compare models with different return windows
affin_base <- ratings %>%
  select(date, Company, reviewtext) %>% 
  unnest_tokens(output = word, input = reviewtext) %>% 
  inner_join(afinn) %>% 
  mutate(y = year(date),
         q = paste0(y, quarter(date)),
         m = paste0(y, month(date))) %>% 
  rename(company = Company)


min(afinn$value)
```

```{r}
# create sentiment analysis for 3 month rolling average
bing <- tidytext::get_sentiments('bing')

bing_nlp <- ratings %>%
  select(date, Company, reviewtext) %>%
  filter(date > "2016-01-01") %>%
  unnest_tokens(output = word, input = reviewtext) %>% 
  anti_join(stop_words) %>% 
  inner_join(bing) %>%
  mutate(month = (ceiling_date(date, unit = 'month') - days(1))) %>%
  group_by(month, Company, sentiment) %>%
  summarise(count = n(), .groups = 'keep') %>% 
  pivot_wider(names_from = sentiment, values_from = count, values_fill = list(count = 0)) %>% 
  mutate(total = positive + negative) %>% 
  mutate(percent_positive = (positive / total) * 100)
  #ggplot(aes(x = month, y = percent_positive, fill = Company)) +
  #geom_bar(stat = 'identity', position = 'stack') +
  #facet_wrap(~Company) + labs(y = 'Percentage Positive', x = '')\


bing_base <- ratings %>%
  select(date, Company, reviewtext) %>%
  unnest_tokens(output = word, input = reviewtext) %>% 
  anti_join(stop_words) %>% 
  inner_join(bing) %>% 
  mutate(y = year(date),
         q = paste0(y, quarter(date)),
         m = paste0(y, month(date))) %>% 
  rename(company = Company) %>% 
  mutate(p_n = case_when(sentiment == 'positive' ~ 1,
                   sentiment == 'negative' ~ 0,
                   T ~ NA))


rev_base <- rbind(bp, chevron, exxon, shell) %>% 
  transmute(ratingValue, name, reviewBody, company = name1, date, i) %>%
  mutate(date = as.Date(date, format = "%b %d, %Y")) %>%
  drop_na() %>% 
  arrange(company, date) %>% 
  mutate(y = year(date),
         q = paste0(y, quarter(date)),
         m = paste0(y, month(date))) 

```

```{r}
# Returns Data
tick <- c('SHEL', 'XOM', 'BP', 'CVX')

prices <- tidyquant::tq_get(tick,
                            get = 'stock.prices',
                            from = '2013-12-31',
                            to = Sys.Date())
ret <- prices %>%
  group_by(symbol) %>%
  mutate(returns = log(adjusted/lag(adjusted))) %>% 
  transmute(date, symbol, returns)

tick <- c('^GSPC')

index <- tidyquant::tq_get(tick,
                           get = 'stock.prices',
                           from = '2013-12-31',
                           to = Sys.Date())

rf <- tidyquant::tq_get("DGS10",
                           get = "economic.data",
                           from = '2013-12-31',
                           to = Sys.Date()) %>% 
  transmute(date, rf = price/100) %>% 
  mutate(rf = ((rf + 1)^(1/252)) - 1) 


ret_index <- index %>%
  group_by(symbol) %>%
  mutate(returns = log(adjusted/lag(adjusted))) %>% 
  ungroup() %>% 
  transmute(date, sp500_close = adjusted, sp500_ret = returns)

#join rf to main returns; missing a few corresonding rf's, hence fill
ret_index <- full_join(rf, ret_index, by = 'date') %>%
  fill(rf, .direction = "down")
  
ret_join <- full_join(ret, ret_index, by = 'date') %>% 
  drop_na()


#div for roll reg
shell_ret <- ret_join %>% 
  filter(symbol == "SHEL")

exon_ret <- ret_join %>% 
  filter(symbol == "XOM")
  
bp_ret <- ret_join %>% 
  filter(symbol == "BP")

chev_ret <- ret_join %>% 
  filter(symbol == "CVX")

chev_ret <- rollReg(chev_ret, 252, 'sp500_ret', 'returns')

bp_ret <- rollReg(bp_ret, 252, 'sp500_ret', 'returns')

exon_ret <- rollReg(exon_ret, 252, 'sp500_ret', 'returns')

shell_ret <- rollReg(shell_ret, 252, 'sp500_ret', 'returns')

# alpha = Rasset - rf - beta*Rmarket + Beta*rf

ret_join_beta <- rbind(chev_ret, bp_ret, exon_ret, shell_ret)

ret_join_beta <- ret_join_beta %>% 
  #daily alpha
  mutate(alpha = returns - rf - slope*sp500_ret + slope*rf) %>% 
  drop_na() %>%
  #y, q, m for summarising 
  mutate(y = year(date),
         q = paste0(y, quarter(date)),
         m = paste0(y, month(date)))



```

```{r}

#old analysis; intial roll test

library(tidyverse)
library(zoo)
library(lubridate)

rateRollAvg <- rbind(bp, chevron, exxon, shell) %>% 
  transmute(ratingValue, name, reviewBody, company = name1, date, i) %>%
  mutate(date = as.Date(date, format = "%b %d, %Y")) %>%
  drop_na() %>% 
  arrange(company, date) %>%
  mutate(month = (ceiling_date(date, unit = 'month') - days(1))) %>% 
  group_by(company, month) %>%
  summarise(meanRateMon = mean(ratingValue)) %>% 
  group_by(company) %>%
  mutate(rollAvg3 = rollmean(meanRateMon, 3, fill = NA, align="right")) %>%
  mutate(rollAvg12 = rollmean(meanRateMon, 12, fill = NA, align="right")) %>% 
  drop_na() %>% 
  filter(month > "2015-12-31") %>% 
  mutate(xOver = case_when(rollAvg3 > rollAvg12 ~ 1,
                           rollAvg3 <= rollAvg12 ~ 0)) %>% 
  ungroup() %>% 
  arrange(month)


bing_nlp <- bing_nlp %>% 
  rename(company = Company)
afinn_nlp <- afinn_nlp %>% 
  rename(company = Company)

review_comb <- full_join(rateRollAvg, bing_nlp, by = c('month', 'company'))
review_comb <- full_join(review_comb, afinn_nlp, by = c('month', 'company'))


```

```{r}
#chunk from initial analysis
tick <- c('SHEL', 'XOM', 'BP', 'CVX')

adj_price <- fintool::ezohlc(tick, '2014-01-01', Sys.Date())

retMon <- adj_price %>%
  mutate(month = (ceiling_date(date, unit = 'month') - days(1))) %>% 
  group_by(month, Symbol) %>% 
  summarise(
    openMon = first(Open),
    closeMon = last(Close)) %>% 
  mutate(retMon = log(closeMon/openMon)) %>% 
  mutate(company = case_when(Symbol == "BP" ~ "bp",
                             Symbol == "CVX" ~ "Chevron",
                             Symbol == "SHEL" ~ "Shell",
                             Symbol == "XOM" ~ "ExxonMobil"))

# for binding to signal df; hypothesis is that indicators predict returns one month ahead. Thus, for model testing sake we need to subtract one month from return df to bind to indicator df
retMon4bind <- retMon %>% 
  mutate(month = (month + days(1)) - months(1) - days(1))

review_comb <- full_join(review_comb, retMon4bind, by = c('month', 'company'))
```

```{r}
#reviews as a predictor of alpha, leading 1 year (y)
rev_y <- rev_base %>% 
  group_by(y, company) %>% 
  summarise(mean_rating = mean(ratingValue), count = n()) 

affin_y <- affin_base %>% 
  group_by(company, y) %>% 
  summarise(sentiment = mean(value))

bing_y <- bing_base %>% 
  group_by(company, y) %>% 
  summarise(prop_postive = mean(p_n))
  
indicators_y <- full_join(rev_y, affin_y, by = c("company", "y"))
indicators_y <- full_join(bing_y, indicators_y, by = c("company", "y"))


alpha_y <- ret_join_beta %>% 
  filter(date >= '2014-12-31',
         date <= '2024-01-01') %>% 
  rename(Symbol = symbol) %>% 
  mutate(company = case_when(Symbol == "BP" ~ "bp",
                             Symbol == "CVX" ~ "Chevron",
                             Symbol == "SHEL" ~ "Shell",
                             Symbol == "XOM" ~ "ExxonMobil")) %>% 
  ungroup() %>% 
  select(-Symbol) %>% 
  group_by(y) %>% 
  filter(date == max(date)) %>% 
  ungroup()

alpha_y <- alpha_y %>% 
  group_by(company) %>% 
  mutate(returns = log(sp500_close/lag(sp500_close)),
         rf = ((rf + 1)^(252)) - 1) %>% 
  mutate(alpha = returns - rf - slope*sp500_ret + slope*rf) %>%
  mutate(y = y - 1) %>% 
  drop_na() %>% 
  group_by(y) 
  

comb_y <- full_join(alpha_y, indicators_y, by = c("company", "y")) %>% 
  transmute(y, date, company, alpha, prop_postive, mean_rating, sentiment) %>% 
  drop_na()

model <- lm(alpha ~ prop_postive + mean_rating + sentiment, data = comb_y)

summary(model)

#tq_index("^GSPC", get = "stock.prices", from = "2020-01-01", to = "2024-01-01")

#sp500_desc <- tidyquant::tq_index("SP500") 
  #%>% dplyr::filter(!stringr::str_detect(symbol,"BRK.B|BF.B"))

#sp400_prices <- tidyquant::tq_get(sort(sp400_desc$symbol),
                                  #sort(grep(sp400_desc$symbol,pattern = "BRK.B|BF.B|DD", value = TRUE, invert = TRUE)),
                             #     get  = "stock.prices",
                             #     from = "2011-01-01",
                               #   to = Sys.Date())

```

```{r}

port_y <- adj_price %>% 
  filter(date >= '2014-12-31',
         date <= '2024-01-01') %>% 
  mutate(company = case_when(Symbol == "BP" ~ "bp",
                             Symbol == "CVX" ~ "Chevron",
                             Symbol == "SHEL" ~ "Shell",
                             Symbol == "XOM" ~ "ExxonMobil")) %>% 
  mutate(y = year(date),
         q = paste0(y, quarter(date)),
         m = paste0(y, month(date))) %>% 
  group_by(y) %>% 
  filter(date == max(date)) %>% 
  ungroup() %>% 
  #subtract a year to bind correct lagged sentiment
  mutate(y = y - 1)

rev_y <- rev_base %>% 
  group_by(y, company) %>% 
  summarise(mean_rating = mean(ratingValue), count = n()) 

affin_y <- affin_base %>% 
  group_by(company, y) %>% 
  summarise(sentiment = mean(value))

bing_y <- bing_base %>% 
  group_by(company, y) %>% 
  summarise(prop_postive = mean(p_n))
  
indicators_y <- full_join(rev_y, affin_y, by = c("company", "y"))
indicators_y <- full_join(bing_y, indicators_y, by = c("company", "y"))

#joining prices at year end with sentiment
port_y <- full_join(port_y, indicators_y, by = c("company", "y"))  %>% 
  select(-count)


port_y_norm <- port_y %>% 
  #normalizing indicators
  mutate(mean_rating = mean_rating/5,
         sentiment = sentiment/5) %>% 
  transmute(date, company, close = Close, y, prop_postive, mean_rating, sentiment) %>% 
  drop_na() %>% 
  mutate(comb_sent = 2*prop_postive + 2*mean_rating + 2*sentiment) %>%
  group_by(y) %>%
  mutate(weight = comb_sent / sum(comb_sent)) %>% 
  group_by(company)

#close prices dictate most of the weight in this simple ex. fyi
weighted_returns <- port_y_norm %>% 
  mutate(w_close = weight*close) %>%
  group_by(date) %>%
  summarise(port_value = sum(w_close)) %>% 
  ungroup() %>% 
  mutate(logRet = log(port_value/lag(port_value))) %>% 
  drop_na() 


# P*L will just be annuual. But how do we look at a timets graph through time? Other methods? 



```

```{r}
# create a weighted portfolio that does not take into account sentiment and backtest it.

# set parameters.

w1 <- 0.25
w2 <- 0.25
w3 <- 0.25
w4 <- 0.25

# write a function that takes the 4 parameters. Do we need to worry about open on the trade date? Depending on position size there could be a big slip, especially pushing 8 trades through when we rebalance. 
# also need to create a dataframe of different weights to run through and backtest after transitioning to a timetk type object.


#function(data = train, w1 = 0.25, w2 = 0.25, w3 = 0.25, w4 = 0.25) {


data <- port_y_norm %>% select(date, close) %>% 
  mutate(weights = case_when(company == 'Shell' ~ w1,
                             company == 'ExxonMobil' ~ w2,
                             company == 'Chevron' ~ w3,
                             TRUE ~ w4)) %>%
  arrange(company, date) %>%
  group_by(company) %>% 
  mutate(previous_weight = lag(weights), # previous weight
         trades = case_when(
           date == '2014-12-31' ~ 1, # Starting strategy
           is.na(previous_weight) ~ NA_real_, # Handle the first row 
           weights < previous_weight ~ -1, # Selling
           weights > previous_weight ~ 1, # Buying
           TRUE ~ 0 # No change
         )) %>%
  ungroup() %>% 
  mutate(position = 4) %>% 
  

#%>% 
  #mutate(w_close = weights*close) %>%
  #group_by(date) %>%
  #summarise(port_value = sum(w_close)) %>% 
  #ungroup() %>% 
  #mutate(logRet = log(port_value/lag(port_value))) %>% 
  #drop_na() %>% mutate(pl = cumprod(1+logRet))



# return(data)
# }
  




port_y_norm <- port_y_norm %>%
  arrange(company, date) %>% # Ensure data is sorted
  group_by(company) %>% # Group by company to apply lag within each company
  mutate(previous_weight = lag(weight), # Create a column for the previous year's weight
         trades = case_when(
           date == '2014-12-31' ~ 1, # Starting strategy
           is.na(previous_weight) ~ NA_real_, # Handle the first row for each company where there's no previous weight
           weight < previous_weight ~ -1, # Selling
           weight > previous_weight ~ 1, # Buying
           TRUE ~ 0 # No change
         )) %>%
  ungroup() 














```

