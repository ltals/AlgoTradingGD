---
title: "NLPGD"
format: html
editor: visual
---

## Preface

Employees are the heart and soul of a business. Their actions and performance are what drive the profitability of a business and it's ability to maximize shareholder value. In the following document, we look to address the following question:

*Is there a relationship between employee sentiment and excess returns?*

By building a webscraping program and applying it to GlassDoor, we were able to compile comprehensive list thousands of employee reviews across a variety of companies:

-   ExxonMobil (XOM)
-   Chevron (CVX)
-   Shell (SHEL)
-   BP (BP)

For context on the analysis that occurs below, here is a chart that represents their respective share prices from the last 10 years:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(tidyquant)
library(plotly)
library(data.table)
library(lubridate)
library(zoo)
library(tidytext)
library(textdata)
library(fintool)
#github: jvlahadamis/fintool

bp <- read_csv("BP.csv") %>% 
  mutate(i = row_number())
chevron <- read_csv("chevron.csv") %>% 
  mutate(i = row_number())
exxon <- read_csv("exxonmobil.csv") %>% 
  mutate(i = row_number())
shell <- read_csv("Shell.csv") %>% 
  mutate(i = row_number())


# my os seems to import them as ...1, hence comment out
bp <- bp %>% 
  #select(-X)
  select(-`...1`)
shell <- shell %>%
  #select(-X)
  select(-`...1`)

# prep dataframe
ratings <- rbind(bp, shell, exxon, chevron)
ratings <- ratings %>%
  mutate('Company' = name1, 
         'reviewtext' = reviewBody,
         'Rating' = ratingValue,
         #lubridate method was giving a parsing error for 3, this way seems quiter
          date = as.Date(date, format = "%b %d, %Y")) %>%
          transmute(Company, name, Rating, reviewtext, date)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# start playing around with sentiment
# afinn
afinn <- tidytext::get_sentiments('afinn')

afinn_nlp <- ratings %>%
  select(date, Company, reviewtext) %>%
  filter(date > "2016-01-01") %>% 
  unnest_tokens(output = word, input = reviewtext) %>% 
  inner_join(afinn) %>%
  mutate(month = (ceiling_date(date, unit = 'month') - days(1))) %>% 
  group_by(month, Company) %>%
  summarise(sentiment = mean(value), .groups = 'keep') 

afinn_nlp %>% 
  ggplot(aes(x = month, y = sentiment, col = Company)) + geom_bar(stat = 'identity') + facet_wrap(~Company)

#unsummarised base files used to compare models with different return windows
affin_base <- ratings %>%
  select(date, Company, reviewtext) %>% 
  unnest_tokens(output = word, input = reviewtext) %>% 
  inner_join(afinn) %>% 
  mutate(y = year(date),
         q = paste0(y, quarter(date)),
         m = paste0(y, month(date))) %>% 
  rename(company = Company)


min(afinn$value)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# create sentiment analysis for 3 month rolling average
bing <- tidytext::get_sentiments('bing')

bing_nlp <- ratings %>%
  select(date, Company, reviewtext) %>%
  filter(date > "2016-01-01") %>%
  unnest_tokens(output = word, input = reviewtext) %>% 
  anti_join(stop_words) %>% 
  inner_join(bing) %>%
  mutate(month = (ceiling_date(date, unit = 'month') - days(1))) %>%
  group_by(month, Company, sentiment) %>%
  summarise(count = n(), .groups = 'keep') %>% 
  pivot_wider(names_from = sentiment, values_from = count, values_fill = list(count = 0)) %>% 
  mutate(total = positive + negative) %>% 
  mutate(percent_positive = (positive / total) * 100)
  #ggplot(aes(x = month, y = percent_positive, fill = Company)) +
  #geom_bar(stat = 'identity', position = 'stack') +
  #facet_wrap(~Company) + labs(y = 'Percentage Positive', x = '')\


bing_base <- ratings %>%
  select(date, Company, reviewtext) %>%
  unnest_tokens(output = word, input = reviewtext) %>% 
  anti_join(stop_words) %>% 
  inner_join(bing) %>% 
  mutate(y = year(date),
         q = paste0(y, quarter(date)),
         m = paste0(y, month(date))) %>% 
  rename(company = Company) %>% 
  mutate(p_n = case_when(sentiment == 'positive' ~ 1,
                   sentiment == 'negative' ~ 0,
                   T ~ NA))


rev_base <- rbind(bp, chevron, exxon, shell) %>% 
  transmute(ratingValue, name, reviewBody, company = name1, date, i) %>%
  mutate(date = as.Date(date, format = "%b %d, %Y")) %>%
  drop_na() %>% 
  arrange(company, date) %>% 
  mutate(y = year(date),
         q = paste0(y, quarter(date)),
         m = paste0(y, month(date))) 

```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Returns Data
tick <- c('SHEL', 'XOM', 'BP', 'CVX')

prices <- tidyquant::tq_get(tick,
                            get = 'stock.prices',
                            from = '2013-12-31',
                            to = Sys.Date())
ret <- prices %>%
  group_by(symbol) %>%
  mutate(returns = log(adjusted/lag(adjusted))) %>% 
  transmute(date, symbol, returns)

tick <- c('^GSPC')

index <- tidyquant::tq_get(tick,
                           get = 'stock.prices',
                           from = '2013-12-31',
                           to = Sys.Date())

rf <- tidyquant::tq_get("DGS10",
                           get = "economic.data",
                           from = '2013-12-31',
                           to = Sys.Date()) %>% 
  transmute(date, rf = price/100) %>% 
  mutate(rf = ((rf + 1)^(1/252)) - 1) 


ret_index <- index %>%
  group_by(symbol) %>%
  mutate(returns = log(adjusted/lag(adjusted))) %>% 
  ungroup() %>% 
  transmute(date, sp500_close = adjusted, sp500_ret = returns)

#join rf to main returns; missing a few corresonding rf's, hence fill
ret_index <- full_join(rf, ret_index, by = 'date') %>%
  fill(rf, .direction = "down")
  
ret_join <- full_join(ret, ret_index, by = 'date') %>% 
  drop_na()


#div for roll reg
shell_ret <- ret_join %>% 
  filter(symbol == "SHEL")

exon_ret <- ret_join %>% 
  filter(symbol == "XOM")
  
bp_ret <- ret_join %>% 
  filter(symbol == "BP")

chev_ret <- ret_join %>% 
  filter(symbol == "CVX")

chev_ret <- rollReg(chev_ret, 252, 'sp500_ret', 'returns')

bp_ret <- rollReg(bp_ret, 252, 'sp500_ret', 'returns')

exon_ret <- rollReg(exon_ret, 252, 'sp500_ret', 'returns')

shell_ret <- rollReg(shell_ret, 252, 'sp500_ret', 'returns')

# alpha = Rasset - rf - beta*Rmarket + Beta*rf

ret_join_beta <- rbind(chev_ret, bp_ret, exon_ret, shell_ret)

ret_join_beta <- ret_join_beta %>% 
  #daily alpha
  mutate(alpha = returns - rf - slope*sp500_ret + slope*rf) %>% 
  drop_na() %>%
  #y, q, m for summarising 
  mutate(y = year(date),
         q = paste0(y, quarter(date)),
         m = paste0(y, month(date)))

```

```{r, echo=FALSE, message=FALSE, warning=FALSE}

#old analysis; intial roll test

library(tidyverse)
library(zoo)
library(lubridate)

rateRollAvg <- rbind(bp, chevron, exxon, shell) %>% 
  transmute(ratingValue, name, reviewBody, company = name1, date, i) %>%
  mutate(date = as.Date(date, format = "%b %d, %Y")) %>%
  drop_na() %>% 
  arrange(company, date) %>%
  mutate(month = (ceiling_date(date, unit = 'month') - days(1))) %>% 
  group_by(company, month) %>%
  summarise(meanRateMon = mean(ratingValue)) %>% 
  group_by(company) %>%
  mutate(rollAvg3 = rollmean(meanRateMon, 3, fill = NA, align="right")) %>%
  mutate(rollAvg12 = rollmean(meanRateMon, 12, fill = NA, align="right")) %>% 
  drop_na() %>% 
  filter(month > "2015-12-31") %>% 
  mutate(xOver = case_when(rollAvg3 > rollAvg12 ~ 1,
                           rollAvg3 <= rollAvg12 ~ 0)) %>% 
  ungroup() %>% 
  arrange(month)


bing_nlp <- bing_nlp %>% 
  rename(company = Company)
afinn_nlp <- afinn_nlp %>% 
  rename(company = Company)

review_comb <- full_join(rateRollAvg, bing_nlp, by = c('month', 'company'))
review_comb <- full_join(review_comb, afinn_nlp, by = c('month', 'company'))


```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#chunk from initial analysis
tick <- c('SHEL', 'XOM', 'BP', 'CVX')

adj_price <- fintool::ezohlc(tick, '2013-01-01', Sys.Date())

retMon <- adj_price %>%
  mutate(month = (ceiling_date(date, unit = 'month') - days(1))) %>% 
  group_by(month, Symbol) %>% 
  summarise(
    openMon = first(Open),
    closeMon = last(Close)) %>% 
  mutate(retMon = log(closeMon/openMon)) %>% 
  mutate(company = case_when(Symbol == "BP" ~ "bp",
                             Symbol == "CVX" ~ "Chevron",
                             Symbol == "SHEL" ~ "Shell",
                             Symbol == "XOM" ~ "ExxonMobil"))

# for binding to signal df; hypothesis is that indicators predict returns one month ahead. Thus, for model testing sake we need to subtract one month from return df to bind to indicator df
retMon4bind <- retMon %>% 
  mutate(month = (month + days(1)) - months(1) - days(1))

review_comb <- full_join(review_comb, retMon4bind, by = c('month', 'company'))
```
# Alpha Analysis
- Using CAPM, Alphas were calculated annually for each individual stock
  - 1 Year Beta
  - S&P500 utilized as a proxy for market return
  
- Annual Alphas were regressed annually against the preceding year's average review ratings and sentiment, as defined by the Affin dictionary.
  - Bing NLP excluded due to model multicollinearity

- Model fit was poor for all four companies

- Alpha between the four firms w
  


```{r, echo=FALSE, message=FALSE, warning=FALSE}
#reviews as a predictor of alpha, leading 1 year (y)
rev_y <- rev_base %>% 
  group_by(y, company) %>% 
  summarise(mean_rating = mean(ratingValue), count = n()) 

affin_y <- affin_base %>% 
  group_by(company, y) %>% 
  summarise(sentiment = mean(value))

bing_y <- bing_base %>% 
  group_by(company, y) %>% 
  summarise(prop_postive = mean(p_n))
  
indicators_y <- full_join(rev_y, affin_y, by = c("company", "y"))
indicators_y <- full_join(bing_y, indicators_y, by = c("company", "y"))


alpha_y <- ret_join_beta %>% 
  filter(date >= '2014-12-31',
         date <= '2024-01-01') %>% 
  rename(Symbol = symbol) %>% 
  mutate(company = case_when(Symbol == "BP" ~ "bp",
                             Symbol == "CVX" ~ "Chevron",
                             Symbol == "SHEL" ~ "Shell",
                             Symbol == "XOM" ~ "ExxonMobil")) %>% 
  ungroup() %>% 
  select(-Symbol) %>% 
  group_by(y) %>% 
  filter(date == max(date)) %>% 
  ungroup()

alpha_y <- alpha_y %>% 
  group_by(company) %>% 
  mutate(returns = log(sp500_close/lag(sp500_close)),
         rf = ((rf + 1)^(252)) - 1) %>% 
  mutate(alpha = returns - rf - slope*sp500_ret + slope*rf) %>%
  mutate(y = y - 1) %>% 
  drop_na() %>% 
  group_by(y) 
  

comb_y <- full_join(alpha_y, indicators_y, by = c("company", "y")) %>% 
  transmute(y, date, company, alpha, prop_postive, mean_rating, sentiment) %>% 
  drop_na()

library(car)

comb_chev <- comb_y %>% 
  filter(company == "Chevron")

model_chev <- lm(alpha ~ prop_postive + mean_rating + sentiment, data = comb_y)

vif(model_chev)

summary(model_chev)

comb_bp <- comb_y %>% 
  filter(company == "bp")

model_bp <- lm(alpha ~ mean_rating + sentiment, data = comb_bp)

summary(model_bp)

vif(model_bp)

comb_exxon <- comb_y %>% 
  filter(company == "ExxonMobil")

model_exxon <- lm(alpha ~ mean_rating + sentiment, data = comb_exxon)

vif(model_exxon)

summary(model_exxon)

comb_shell <- comb_y %>% 
  filter(company == "Shell")

model_shell <- lm(alpha ~ mean_rating + sentiment, data = comb_shell)

summary(model_shell)

vif(model_shell)

wide_alpha <- alpha_y %>%
  ungroup() %>% 
  transmute(company, date, alpha) %>%  
  pivot_wider(names_from = company, values_from = alpha)  %>% 
  select(-date)


stats::cor(wide_alpha, method = "pearson")
  
  , method = "number", type = "upper",tl.col="grey30", tl.srt=45, addCoef.col = 'grey30')

corrplot::corrplot.mixed(stats::cor(wide_alpha, method = "pearson"), title = "Correlation Matrix", upper = "number", lower = "square", tl.pos = 'd', tl.col="black", tl.srt=45, addCoef.col = 'grey20', mar=c(0,0,2,0))


#uso <- tq_get("USO", from = "2014-01-01", to = "2023-12-31") %>%
#  mutate(y = year(date)) %>% 
#  group_by(y) %>% 
#  filter(date == max(date)) %>% 
#  ungroup()  %>% 
#mutate(logRet = log(adjusted/lag(adjusted))) %>% 
#  drop_na()


#test <- full_join(alpha_y, uso, by = "date") 

#test %>% 
#  ggplot(aes(x = date, y = alpha, col = company)) + geom_line() +
 # geom_line(y = $logRet)


#model_uso <- lm(alpha ~ adjusted, data = test)

#summary(model_uso)
```

# Portfolio-based Analysis
#### Two portfolios of our selected companies were created

- Portflio 1: Naive equally-weighted portfolio
  - Rebalanced yearly based upon the prior years closing price

- Portfolio 2: Optimized portfolio utilizing three sentiment indicators
  - Generated weights utilizing a combination the input indicators
  - Optimization process to determine the ideal relative sentiment mix
    - Training window: 2014-2021
  - Rebalanced annually using an aggregation sentiment data from the prior year
    - Sentiment is treated on a absolute basis as opposed to on a relative basis to prior years
    - Companies are proportional de-weighted in cases of 'review slippage' relative to their peers
      - No additionally compounds are included for +/- review drift 



```{r, echo=FALSE, message=FALSE, warning=FALSE}

port_y <- adj_price %>% 
  filter(date >= '2013-12-31',
         date <= '2024-01-01') %>% 
  mutate(company = case_when(Symbol == "BP" ~ "bp",
                             Symbol == "CVX" ~ "Chevron",
                             Symbol == "SHEL" ~ "Shell",
                             Symbol == "XOM" ~ "ExxonMobil")) %>% 
  mutate(y = year(date),
         q = paste0(y, quarter(date)),
         m = paste0(y, month(date))) %>% 
  group_by(y) %>% 
  filter(date == max(date)) %>% 
  ungroup() %>% 
  #subtract a year to bind correct lagged sentiment
  mutate(y = y - 1) %>% 
  group_by(company) %>% 
  mutate(lag_close = lag(Close)) %>% 
  drop_na()

rev_y <- rev_base %>% 
  group_by(y, company) %>% 
  summarise(mean_rating = mean(ratingValue), count = n()) 

affin_y <- affin_base %>% 
  group_by(company, y) %>% 
  summarise(sentiment = mean(value))

bing_y <- bing_base %>% 
  group_by(company, y) %>% 
  summarise(prop_postive = mean(p_n))
  
indicators_y <- full_join(rev_y, affin_y, by = c("company", "y"))
indicators_y <- full_join(bing_y, indicators_y, by = c("company", "y"))

#joining prices at year end with sentiment
port_y <- full_join(port_y, indicators_y, by = c("company", "y"))  %>% 
  select(-count)

```

```{r, echo=FALSE, message=FALSE, warning=FALSE}


port_y_train <- port_y %>% 
  filter(date < '2020-12-31')

trade_func <- function(data, prop, rate, sent) {
  port_y_norm <- data %>% 
  #normalizing indicators
  mutate(mean_rating = mean_rating,
         sentiment = sentiment) %>% 
  transmute(date, company, close = Close, y, prop_postive, mean_rating, sentiment, lag_close) %>% 
  drop_na() %>% 
  mutate(comb_sent = prop*prop_postive + rate*mean_rating + sent*sentiment,
         price_norm = 1 / lag_close) %>% 
  group_by(y) %>% 
  #weighted sentiment
  mutate(weight_sent = comb_sent / sum(comb_sent)) %>%
  #adj for close prices in the prior year
  mutate(weight = weight_sent*price_norm/sum(price_norm*weight_sent)) %>%
  arrange(company, date) %>%
  group_by(company) %>% 
  mutate(previous_weight = lag(weight), # previous weight
         trades = case_when(
           date == '2015-12-31' ~ 1, # Starting strategy
           is.na(previous_weight) ~ NA_real_, # Handle the first row 
           weight < previous_weight ~ -1, # Selling
           weight > previous_weight ~ 1, # Buying
           TRUE ~ 0 # No change
         )) %>%
  ungroup() %>% 
  mutate(position = 4)
  
  weighted_returns <- port_y_norm %>% 
  mutate(w_close = weight*close) %>%
  group_by(date) %>%
  summarise(port_value = sum(w_close)) %>% 
  ungroup() %>% 
  mutate(logRet = log(port_value/lag(port_value))) %>% 
  drop_na() %>% 
  summarise(logRet_sum = sum(logRet),
            var = var(logRet)) %>% 
  mutate(prop = prop, 
         rate = rate,
         sent = sent)
  
    return(weighted_returns) 
  }


trade_func(port_y, 0, 1, 0)

out <- expand.grid(
  prop = seq(from = 0, to = 1, by = .02),
  rate = seq(from = 0, to = 1, by = .02),
  sent = seq(from = 0, to = 1, by = .02)) %>% 
  mutate(total = prop + rate + sent) %>% 
  filter(total == 1)
  

library(foreach)
library(doParallel)

n_cores <- detectCores() - 1

cl <- makeCluster(n_cores)
registerDoParallel(cl)

res <- foreach(
  combo = iter(out, by = 'row'), 
  .combine = rbind,
  .packages = c("dplyr", "tidyverse", "tidyquant", "PerformanceAnalytics") 
) %dopar% {

  prop <- combo$prop
  rate <- combo$rate
  sent <- combo$sent
  
 
  trade_func(data = port_y_train, prop = prop, rate = rate, sent = sent)
}


stopCluster(cl)




rebal_func <- function(data) {
  port_y_norm <- data %>% 
  transmute(date, company, close = Close, y, lag_close) %>% 
  drop_na() %>% 
  mutate(price_norm = 1 / lag_close) %>% 
  group_by(y) %>%
  #adj for close prices in the prior year
  mutate(weight = price_norm/sum(price_norm)) %>%
  arrange(company, date) %>%
  group_by(company) %>% 
  mutate(previous_weight = lag(weight), # previous weight
         trades = case_when(
           date == '2015-12-31' ~ 1, # Starting strategy
           is.na(previous_weight) ~ NA_real_, # Handle the first row 
           weight < previous_weight ~ -1, # Selling
           weight > previous_weight ~ 1, # Buying
           TRUE ~ 0 # No change
         )) %>%
  ungroup() %>% 
  mutate(position = 4)
  
  weighted_returns <- port_y_norm %>% 
  mutate(w_close = weight*close) %>%
  group_by(date) %>%
  summarise(port_value = sum(w_close)) %>% 
  ungroup() %>% 
  mutate(logRet = log(port_value/lag(port_value))) %>% 
  drop_na() %>% 
  summarise(logRet_sum = sum(logRet),
            var = var(logRet)) 
  
    return(weighted_returns) 
  }


rebal_func(port_y)


port_y_norm <- port_y %>% 
  #normalizing indicators
  mutate(mean_rating = mean_rating/5,
         sentiment = sentiment/5) %>% 
  transmute(date, company, close = Close, y, prop_postive, mean_rating, sentiment, lag_close) %>% 
  drop_na() %>% 
  mutate(comb_sent = 0*prop_postive + 0*mean_rating + 1*sentiment,
         price_norm = 1 / lag_close) %>% 
  group_by(y) %>% 
  #weighted sentiment
  mutate(weight_sent = comb_sent / sum(comb_sent)) %>%
  #adj for close prices in the prior year
  mutate(weight = weight_sent*price_norm/sum(price_norm*weight_sent)) %>%
  arrange(company, date) %>%
  group_by(company) %>% 
  mutate(previous_weight = lag(weight), # previous weight
         trades = case_when(
           date == '2014-12-31' ~ 1, # Starting strategy
           is.na(previous_weight) ~ NA_real_, # Handle the first row 
           weight < previous_weight ~ -1, # Selling
           weight > previous_weight ~ 1, # Buying
           TRUE ~ 0 # No change
         )) %>%
  ungroup() %>% 
  mutate(position = 4)

  
weighted_returns <- port_y_norm %>% 
  mutate(w_close = weight*close) %>%
  group_by(date) %>%
  summarise(port_value = sum(w_close)) %>% 
  ungroup() %>% 
  mutate(logRet = log(port_value/lag(port_value))) %>% 
  drop_na() %>% 
  summarise(logRet_sum = sum(logRet),
            var = var(logRet)) %>% 
  mutate(prop = 0, 
         rate = 0,
         sent = 1)
  

  
port_rebal <- port_y %>% 
  transmute(date, company, close = Close, y, lag_close) %>% 
  drop_na() %>% 
  mutate(price_norm = 1 / lag_close) %>% 
  group_by(y) %>%
  #adj for close prices in the prior year
  mutate(weight = price_norm/sum(price_norm)) %>%
  arrange(company, date) %>%
  group_by(company) %>% 
  mutate(previous_weight = lag(weight), # previous weight
         trades = case_when(
           date == '2015-12-31' ~ 1, # Starting strategy
           is.na(previous_weight) ~ NA_real_, # Handle the first row 
           weight < previous_weight ~ -1, # Selling
           weight > previous_weight ~ 1, # Buying
           TRUE ~ 0 # No change
         )) %>%
  ungroup() %>% 
  mutate(position = 4)
  
  weighted_returns <- port_rebal %>% 
  mutate(w_close = weight*close) %>%
  group_by(date) %>%
  summarise(port_value = sum(w_close)) %>% 
  ungroup() %>% 
  mutate(logRet = log(port_value/lag(port_value))) %>% 
  drop_na() %>% 
  summarise(logRet_sum = sum(logRet),
            var = var(logRet)) 
    
  
  weighted_close <- port_y_norm %>% 
  mutate(w_close = weight*close) %>%
  group_by(date) %>%
  summarise(port_value = sum(w_close)) %>% 
  ungroup() %>% 
  mutate(logRet = log(port_value/lag(port_value)))
  
  
  weighted_close_rebal <- port_rebal %>% 
  mutate(w_close = weight*close) %>%
  group_by(date) %>%
  summarise(port_value = sum(w_close)) %>% 
  ungroup() %>% 
  mutate(logRet = log(port_value/lag(port_value)))%>%
  group_by(date) %>% 
  summarise(port_value = sum(port_value))
  
portVal_plot <- weighted_close %>% 
  mutate(Year = year(date)) %>%
  group_by(Year) %>% 
  summarise(Sentiment = sum(port_value)) %>% 
  mutate(`Naive` = weighted_close_rebal$port_value) %>% 
  pivot_longer(-Year, names_to = "Portfolio", values_to = "Value") %>% 
  ggplot(aes(y = Value, x = Year, col = Portfolio)) + geom_line() +
  labs(x = "", y = "Porfolio Value", title = "Portfolio Comparison (Test & Train)", subtitle = "Training Window: 2014 - 2020") + theme_minimal()
                    
library(plotly)                       
ggplotly(portVal_plot)                              
   
   
   
  
  
  
```
#```{r}

port_y <- adj_price %>% 
  filter(date >= '2013-12-31',
         date <= '2024-01-01') %>% 
  mutate(company = case_when(Symbol == "BP" ~ "bp",
                             Symbol == "CVX" ~ "Chevron",
                             Symbol == "SHEL" ~ "Shell",
                             Symbol == "XOM" ~ "ExxonMobil")) %>% 
  mutate(year = year(date),
         y = as.numeric(paste0(year, quarter(date))),
         m = paste0(year, month(date))) %>% 
  group_by(y) %>% 
  filter(date == max(date)) %>% 
  ungroup() %>% 
  #subtract a year to bind correct lagged sentiment
  mutate(y = y - 1) %>% 
  group_by(company) %>% 
  mutate(lag_close = lag(Close)) %>% 
  drop_na()

rev_y <- rev_base %>% 
  group_by(q, company) %>% 
  select(-y) %>% 
  rename(y = q) %>%
  mutate(y = as.numeric(y)) %>% 
  summarise(mean_rating = mean(ratingValue), count = n()) 

affin_y <- affin_base %>% 
  group_by(company, q) %>% 
  select(-y) %>% 
  rename(y = q) %>%
  mutate(y = as.numeric(y)) %>% 
  summarise(sentiment = mean(value))

bing_y <- bing_base %>% 
  group_by(company, q) %>%
  select(-y) %>% 
  rename(y = q) %>%
  mutate(y = as.numeric(y)) %>% 
  summarise(prop_postive = mean(p_n))
  
indicators_y <- full_join(rev_y, affin_y, by = c("company", "y"))
indicators_y <- full_join(bing_y, indicators_y, by = c("company", "y"))

#joining prices at year end with sentiment
port_y <- full_join(port_y, indicators_y, by = c("company", "y"))  %>% 
  select(-count)




port_y_train <- port_y %>% 
  filter(date < '2022-12-31')

trade_func <- function(data, prop, rate, sent) {
  port_y_norm <- data %>% 
  #normalizing indicators
  mutate(mean_rating = mean_rating/5,
         sentiment = sentiment/5) %>% 
  transmute(date, company, close = Close, y, prop_postive, mean_rating, sentiment, lag_close) %>% 
  drop_na() %>% 
  mutate(comb_sent = prop*prop_postive + rate*mean_rating + sent*sentiment,
         price_norm = 1 / lag_close) %>% 
  group_by(y) %>% 
  #weighted sentiment
  mutate(weight_sent = comb_sent / sum(comb_sent)) %>%
  #adj for close prices in the prior year
  mutate(weight = weight_sent*price_norm/sum(price_norm*weight_sent)) %>%
  arrange(company, date) %>%
  group_by(company) %>% 
  mutate(previous_weight = lag(weight), # previous weight
         trades = case_when(
           date == '2015-12-31' ~ 1, # Starting strategy
           is.na(previous_weight) ~ NA_real_, # Handle the first row 
           weight < previous_weight ~ -1, # Selling
           weight > previous_weight ~ 1, # Buying
           TRUE ~ 0 # No change
         )) %>%
  ungroup() %>% 
  mutate(position = 4)
  
  weighted_returns <- port_y_norm %>% 
  mutate(w_close = weight*close) %>%
  group_by(date) %>%
  summarise(port_value = sum(w_close)) %>% 
  ungroup() %>% 
  mutate(logRet = log(port_value/lag(port_value))) %>% 
  drop_na() %>% 
  summarise(logRet_sum = sum(logRet),
            var = var(logRet)) %>% 
  mutate(prop = prop, 
         rate = rate,
         sent = sent)
  
    return(weighted_returns) 
  }


trade_func(port_y, 0, 1, 0)

out <- expand.grid(
  prop = seq(from = 0, to = 1, by = .02),
  rate = seq(from = 0, to = 1, by = .02),
  sent = seq(from = 0, to = 1, by = .02)) %>% 
  mutate(total = prop + rate + sent) %>% 
  filter(total == 1)
  

library(foreach)
library(doParallel)

n_cores <- detectCores() - 1

cl <- makeCluster(n_cores)
registerDoParallel(cl)

res <- foreach(
  combo = iter(out, by = 'row'), 
  .combine = rbind,
  .packages = c("dplyr", "tidyverse", "tidyquant", "PerformanceAnalytics") 
) %dopar% {

  prop <- combo$prop
  rate <- combo$rate
  sent <- combo$sent
  
 
  trade_func(data = port_y_train, prop = prop, rate = rate, sent = sent)
}


stopCluster(cl)




rebal_func <- function(data) {
  port_y_norm <- data %>% 
  transmute(date, company, close = Close, y, lag_close) %>% 
  drop_na() %>% 
  mutate(price_norm = 1 / lag_close) %>% 
  group_by(y) %>%
  #adj for close prices in the prior year
  mutate(weight = price_norm/sum(price_norm)) %>%
  arrange(company, date) %>%
  group_by(company) %>% 
  mutate(previous_weight = lag(weight), # previous weight
         trades = case_when(
           date == '2015-12-31' ~ 1, # Starting strategy
           is.na(previous_weight) ~ NA_real_, # Handle the first row 
           weight < previous_weight ~ -1, # Selling
           weight > previous_weight ~ 1, # Buying
           TRUE ~ 0 # No change
         )) %>%
  ungroup() %>% 
  mutate(position = 4)
  
  weighted_returns <- port_y_norm %>% 
  mutate(w_close = weight*close) %>%
  group_by(date) %>%
  summarise(port_value = sum(w_close)) %>% 
  ungroup() %>% 
  mutate(logRet = log(port_value/lag(port_value))) %>% 
  drop_na() %>% 
  summarise(logRet_sum = sum(logRet),
            var = var(logRet)) 
  
    return(weighted_returns) 
  }


rebal_func(port_y)


  port_y_norm <- port_y %>% 
  #normalizing indicators
  mutate(mean_rating = mean_rating/5,
         sentiment = sentiment/5) %>% 
  transmute(date, company, close = Close, y, prop_postive, mean_rating, sentiment, lag_close) %>% 
  drop_na() %>% 
  mutate(comb_sent = 0*prop_postive + 1*mean_rating + 0*sentiment,
         price_norm = 1 / lag_close) %>% 
  group_by(y) %>% 
  #weighted sentiment
  mutate(weight_sent = comb_sent / sum(comb_sent)) %>%
  #adj for close prices in the prior year
  mutate(weight = weight_sent*price_norm/sum(price_norm*weight_sent)) %>%
  arrange(company, date) %>%
  group_by(company) %>% 
  mutate(previous_weight = lag(weight), # previous weight
         trades = case_when(
           date == '2014-12-31' ~ 1, # Starting strategy
           is.na(previous_weight) ~ NA_real_, # Handle the first row 
           weight < previous_weight ~ -1, # Selling
           weight > previous_weight ~ 1, # Buying
           TRUE ~ 0 # No change
         )) %>%
  ungroup() %>% 
  mutate(position = 4)

  
  weighted_returns <- port_y_norm %>% 
  mutate(w_close = weight*close) %>%
  group_by(date) %>%
  summarise(port_value = sum(w_close)) %>% 
  ungroup() %>% 
  mutate(logRet = log(port_value/lag(port_value))) %>% 
  drop_na() %>% 
  summarise(logRet_sum = sum(logRet),
            var = var(logRet)) %>% 
  mutate(prop = 0, 
         rate = 0,
         sent = 1)
  
  weighted_close <- port_y_norm %>% 
    mutate(w_close = weight*close)
  
   weighted_close %>% 
     mutate(Year = year(date)) %>%
     ggplot(aes(y = port_value, x = y, col = company)) + geom_line()
  

```

